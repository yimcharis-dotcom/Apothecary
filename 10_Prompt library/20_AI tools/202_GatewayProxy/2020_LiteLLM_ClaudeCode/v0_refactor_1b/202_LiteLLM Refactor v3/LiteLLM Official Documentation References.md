---
tags: [litellm, official-docs, references, documentation]
created: 2025-02-11
status: complete
---

# LiteLLM Official Documentation References

Complete reference to official LiteLLM documentation and resources for your setup.

## ğŸ“– Core Documentation

### Main Docs
- **ğŸ  Official Website:** https://docs.litellm.ai/
- **ğŸ“š Getting Started:** https://docs.litellm.ai/docs/
- **âš¡ Quick Start:** https://docs.litellm.ai/docs/simple_proxy
- **ğŸ™ GitHub Repository:** https://github.com/BerriAI/litellm

### API Reference
- **ğŸ”— Swagger API:** https://litellm-api.up.railway.app/
- **ğŸ¤– Model Cost Map:** https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
- **ğŸ’¸ Live Cost Tracker:** https://models.litellm.ai/

## ğŸ”§ Configuration & Setup

### Configuration Files
- **âš™ï¸ Config.yaml Guide:** https://docs.litellm.ai/docs/proxy/configs
- **ğŸ”‘ Environment Variables:** https://docs.litellm.ai/docs/proxy/enterprise
- **ğŸŒ Proxy Deployment:** https://docs.litellm.ai/docs/proxy/quick_start
- **ğŸ³ Docker Setup:** https://docs.litellm.ai/docs/proxy/docker_quick_start

### Authentication & Security
- **ğŸ” Virtual Keys:** https://docs.litellm.ai/docs/proxy/virtual_keys
- **ğŸ›¡ï¸ Guardrails:** https://docs.litellm.ai/docs/proxy/guardrails/quick_start
- **ğŸ“‹ User Management:** https://docs.litellm.ai/docs/proxy/users

## ğŸ’° Cost Management & Tracking

### Spend Tracking
- **ğŸ“Š Cost Tracking:** https://docs.litellm.ai/docs/proxy/cost_tracking
- **ğŸ·ï¸ Request Tags:** https://docs.litellm.ai/docs/proxy/request_tags
- **ğŸ’¸ Custom Pricing:** https://docs.litellm.ai/docs/proxy/custom_pricing
- **ğŸ§® Pricing Calculator:** https://docs.litellm.ai/docs/proxy/pricing_calculator

### Budgets & Limits
- **ğŸ’³ Budget Management:** https://docs.litellm.ai/docs/budget_manager
- **â±ï¸ Rate Limiting:** https://docs.litellm.ai/docs/proxy/users#set-rate-limits
- **ğŸ“ˆ Usage Analytics:** https://docs.litellm.ai/docs/proxy/dynamic_logging

## ğŸ”„ Model Management

### Auto-Sync & Updates
- **ğŸ”„ Auto-Sync Models:** https://docs.litellm.ai/docs/proxy/sync_models_github
- **ğŸ¤– Model Access:** https://docs.litellm.ai/docs/proxy/model_access_guide
- **ğŸ“‹ Supported Models:** https://docs.litellm.ai/docs/providers

### Routing & Load Balancing
- **ğŸ”„ Router Configuration:** https://docs.litellm.ai/docs/routing-load-balancing
- **âš–ï¸ Load Balancing:** https://docs.litellm.ai/docs/routing-load-balancing
- **ğŸ”„ Fallbacks:** https://docs.litellm.ai/docs/routing-load-balancing
- **ğŸ§ª A/B Testing:** https://docs.litellm.ai/docs/traffic_mirroring

## ğŸš€ Advanced Features

### Enterprise
- **ğŸ¢ Enterprise Features:** https://docs.litellm.ai/docs/proxy/enterprise
- **ğŸ“Š Billing & Invoicing:** https://docs.litellm.ai/docs/proxy/billing
- **ğŸ”§ Management CLI:** https://docs.litellm.ai/docs/proxy/management_cli
- **ğŸ” Secret Managers:** https://docs.litellm.ai/docs/secret_managers/overview

### Performance & Monitoring
- **ğŸ“ˆ Caching:** https://docs.litellm.ai/docs/proxy/caching
- **ğŸ“Š Logging & Metrics:** https://docs.litellm.ai/docs/proxy/dynamic_logging
- **âš¡ Performance Tuning:** https://docs.litellm.ai/docs/benchmarks
- **ğŸ” Observability:** https://docs.litellm.ai/docs/observability/callbacks

### Specialized Gateways
- **ğŸ¤– A2A Agent Gateway:** https://docs.litellm.ai/docs/a2a
- **ğŸ”Œ MCP Gateway:** https://docs.litellm.ai/docs/mcp

## ğŸ”Œ Integrations

### AI Tools Integration
- **ğŸ¤– Claude Code:** https://docs.litellm.ai/docs/ai_tools
- **ğŸ§  LangChain:** https://docs.litellm.ai/docs/tutorials/langchain
- **ğŸ¦œ LlamaIndex:** https://docs.litellm.ai/docs/tutorials/llamaindex

### Observability Platforms
- **ğŸ“Š Langfuse:** https://docs.litellm.ai/docs/observability/langfuse_callback
- **ğŸ”­ Lunary:** https://docs.litellm.ai/docs/observability/lunary_callback
- **ğŸŒ€ Helicone:** https://docs.litellm.ai/docs/observability/helicone_callback
- **ğŸ“ˆ MLflow:** https://docs.litellm.ai/docs/observability/mlflow_callback

## ğŸ› ï¸ Development & Troubleshooting

### Development
- **ğŸ”§ Local Development:** https://docs.litellm.ai/docs/extras/contributing_code
- **ğŸ§ª Testing:** https://docs.litellm.ai/docs/troubleshoot
- **ğŸ› Issue Reporting:** https://docs.litellm.ai/docs/troubleshoot/prisma_migrations

### Troubleshooting
- **ğŸš¨ Common Issues:** https://docs.litellm.ai/docs/troubleshoot
- **ğŸ“ Migration Guides:** https://docs.litellm.ai/docs/troubleshoot/prisma_migrations
- **ğŸ” Debug Mode:** Use `--detailed_debug` flag

## ğŸŒ Community & Support

### Getting Help
- **ğŸ’¬ Discord Community:** https://www.litellm.ai/support
- **ğŸ› GitHub Issues:** https://github.com/BerriAI/litellm/issues
- **ğŸ“§ Support Email:** support@litellm.ai
- **ğŸ“… Calendar Booking:** https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat

### Social & Updates
- **ğŸ¦ Twitter:** https://twitter.com/LiteLLM
- **ğŸ“ Blog:** https://www.litellm.ai/blog
- **ğŸ“ˆ Release Notes:** https://github.com/BerriAI/litellm/releases

## ğŸ“‹ Quick Reference Cards

### Environment Variables
```bash
# Core
LITELLM_MASTER_KEY=sk-your-master-key
DATABASE_URL=sqlite:///path/to/litellm.db

# Auto-sync
LITELLM_MODEL_COST_MAP_URL=https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json
LITELLM_LOCAL_MODEL_COST_MAP=true

# Debug
LITELLM_DEBUG=true
```

### Common API Endpoints
```bash
# Health check
GET /health

# Models list
GET /v1/models

# Spend tracking
GET /global/spend/report
GET /spend/logs

# Sync management
POST /reload/model_cost_map
POST /schedule/model_cost_map_reload?hours=6
GET /schedule/model_cost_map_reload/status
```

### Configuration Snippets
```yaml
litellm_settings:
  master_key: "sk-your-master-key"
  set_verbose: true
  drop_params: true
  track_cost: true

general_settings:
  database_url: "sqlite:///litellm.db"
  store_model_in_db: true

router_settings:
  model_group_alias:
    "gpt4": "openai/gpt-4"
    "claude": "anthropic/claude-3-sonnet"
```

## ğŸ¯ Your Setup References

Your current configuration matches these official guides:

1. **ğŸ“– Startup Guide** â†’ Official: https://docs.litellm.ai/docs/proxy/quick_start
2. **ğŸ’° Cost Tracking** â†’ Official: https://docs.litellm.ai/docs/proxy/cost_tracking  
3. **ğŸ”„ Auto-Sync** â†’ Official: https://docs.litellm.ai/docs/proxy/sync_models_github
4. **ğŸ¤– Model Config** â†’ Official: https://docs.litellm.ai/docs/proxy/configs

## ğŸ“š Learning Resources

### Tutorials
- **ğŸš€ Quick Start Tutorial:** https://docs.litellm.ai/docs/proxy/docker_quick_start
- **ğŸ“Š Budget Management:** https://docs.litellm.ai/docs/budget_manager
- **ğŸ”Œ AI Tools Integration:** https://docs.litellm.ai/docs/ai_tools

### Best Practices
- **ğŸ›¡ï¸ Security Best Practices:** https://docs.litellm.ai/docs/proxy/virtual_keys
- **âš¡ Performance Tips:** https://docs.litellm.ai/docs/benchmarks
- **ğŸ’° Cost Optimization:** https://docs.litellm.ai/docs/proxy/cost_tracking

## ğŸ”„ Version Information

- **Current Stable:** Check [GitHub Releases](https://github.com/BerriAI/litellm/releases)
- **Your Version:** 1.81.1 (from installation docs)
- **Update:** `pip install --upgrade litellm[proxy]`

---

## ğŸ’¡ Pro Tips

1. **ğŸ“š Bookmark Key Pages:** Save the main docs and Swagger API
2. **ğŸ”” Enable Updates:** Watch GitHub repo for releases
3. **ğŸ’¬ Join Community:** Discord for real-time help
4. **ğŸ§ª Test Features:** Use demo.cloud.litellm.ai for testing
5. **ğŸ“Š Monitor Costs:** Regular check-ins with spend tracking

## ğŸ†˜ Quick Help Commands

```powershell
# Check proxy status
curl http://localhost:4000/health

# View models
curl http://localhost:4000/v1/models

# Check spend
.\scr\view-spend.ps1

# Sync models
.\scr\sync-models.ps1

# Monitor logs
Get-Content "C:\Users\YC\LiteLLM\logs\proxy.log" -Tail 50
```

---

*This document is maintained as part of your LiteLLM setup. Check the official docs for the most current information.*