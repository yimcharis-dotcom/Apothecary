{
  "version": 12,
  "providers": [
    {
      "type": "openai",
      "id": "openai"
    },
    {
      "type": "anthropic",
      "id": "anthropic"
    },
    {
      "type": "gemini",
      "id": "gemini"
    },
    {
      "type": "deepseek",
      "id": "deepseek"
    },
    {
      "type": "perplexity",
      "id": "perplexity",
      "apiKey": "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"
    },
    {
      "type": "groq",
      "id": "groq"
    },
    {
      "type": "mistral",
      "id": "mistral"
    },
    {
      "type": "openrouter",
      "id": "openrouter"
    },
    {
      "type": "ollama",
      "id": "ollama"
    },
    {
      "type": "lm-studio",
      "id": "lm-studio"
    },
    {
      "type": "morph",
      "id": "morph"
    },
    {
      "type": "openai-compatible",
      "id": "Grok",
      "baseUrl": "https://api.x.ai/v1",
      "apiKey": "xai-ap3FR5Oo56oqBOAapUvEmH6XUKwL3bBysMNu5POmqRvkZedTDMMGdUs2KelXRQT43TD0nxRnZeaxRDMk",
      "additionalSettings": {
        "noStainless": true
      }
    }
  ],
  "chatModels": [
    {
      "providerType": "anthropic",
      "providerId": "anthropic",
      "id": "claude-opus-4.1",
      "model": "claude-opus-4-1",
      "enable": false
    },
    {
      "providerType": "anthropic",
      "providerId": "anthropic",
      "id": "claude-sonnet-4.5",
      "model": "claude-sonnet-4-5",
      "enable": false
    },
    {
      "providerType": "anthropic",
      "providerId": "anthropic",
      "id": "claude-haiku-4.5",
      "model": "claude-haiku-4-5",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "gpt-5",
      "model": "gpt-5",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "gpt-5-mini",
      "model": "gpt-5-mini",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "gpt-5-nano",
      "model": "gpt-5-nano",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "gpt-4.1",
      "model": "gpt-4.1",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "gpt-4.1-mini",
      "model": "gpt-4.1-mini",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "gpt-4.1-nano",
      "model": "gpt-4.1-nano",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "gpt-4o",
      "model": "gpt-4o",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "gpt-4o-mini",
      "model": "gpt-4o-mini",
      "enable": false
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "o4-mini",
      "model": "o4-mini",
      "enable": false,
      "reasoning": {
        "enabled": true,
        "reasoning_effort": "medium"
      }
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "o3",
      "model": "o3",
      "enable": false,
      "reasoning": {
        "enabled": true,
        "reasoning_effort": "medium"
      }
    },
    {
      "providerType": "gemini",
      "providerId": "gemini",
      "id": "gemini-2.5-pro",
      "model": "gemini-2.5-pro",
      "enable": false
    },
    {
      "providerType": "gemini",
      "providerId": "gemini",
      "id": "gemini-2.5-flash",
      "model": "gemini-2.5-flash",
      "enable": false
    },
    {
      "providerType": "gemini",
      "providerId": "gemini",
      "id": "gemini-2.5-flash-lite",
      "model": "gemini-2.5-flash-lite",
      "enable": false
    },
    {
      "providerType": "gemini",
      "providerId": "gemini",
      "id": "gemini-2.0-flash",
      "model": "gemini-2.0-flash",
      "enable": false
    },
    {
      "providerType": "gemini",
      "providerId": "gemini",
      "id": "gemini-2.0-flash-lite",
      "model": "gemini-2.0-flash-lite",
      "enable": false
    },
    {
      "providerType": "deepseek",
      "providerId": "deepseek",
      "id": "deepseek-chat",
      "model": "deepseek-chat",
      "enable": false
    },
    {
      "providerType": "deepseek",
      "providerId": "deepseek",
      "id": "deepseek-reasoner",
      "model": "deepseek-reasoner",
      "enable": false
    },
    {
      "providerType": "perplexity",
      "providerId": "perplexity",
      "id": "sonar",
      "model": "sonar",
      "web_search_options": {
        "search_context_size": "low"
      }
    },
    {
      "providerType": "perplexity",
      "providerId": "perplexity",
      "id": "sonar-pro",
      "model": "sonar",
      "web_search_options": {
        "search_context_size": "low"
      }
    },
    {
      "providerType": "perplexity",
      "providerId": "perplexity",
      "id": "sonar-deep-research",
      "model": "sonar-deep-research",
      "web_search_options": {
        "search_context_size": "low"
      }
    },
    {
      "providerType": "perplexity",
      "providerId": "perplexity",
      "id": "sonar-reasoning",
      "model": "sonar",
      "web_search_options": {
        "search_context_size": "low"
      }
    },
    {
      "providerType": "perplexity",
      "providerId": "perplexity",
      "id": "sonar-reasoning-pro",
      "model": "sonar",
      "web_search_options": {
        "search_context_size": "low"
      }
    },
    {
      "providerType": "morph",
      "providerId": "morph",
      "id": "morph-v0",
      "model": "morph-v0",
      "enable": false
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "gemma2:9b",
      "model": "gemma2:9b",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "qwen2.5:3b",
      "model": "qwen2.5:3b",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "gemma2:2b",
      "model": "gemma2:2b",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "llama3.2:latest",
      "model": "llama3.2:latest",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "llama3_1:latest",
      "model": "llama3_1:latest",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "qwen2.5:7b-instruct",
      "model": "qwen2.5:7b-instruct",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "mistral-4k:latest",
      "model": "mistral-4k:latest",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "openai-compatible",
      "providerId": "Grok",
      "id": "grok-3",
      "model": "grok-3",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "openai-compatible",
      "providerId": "Grok",
      "id": "grok-4-fast-non-reasoning",
      "model": "grok-4-fast-non-reasoning",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "openai-compatible",
      "providerId": "Grok",
      "id": "grok-2-vision-1212",
      "model": "grok-2-vision-1212",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "openai-compatible",
      "providerId": "Grok",
      "id": "grok-4-1-fast-non-reasoning",
      "model": "grok-4-1-fast-non-reasoning",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "phi3-new:latest",
      "model": "phi3-new:latest",
      "promptLevel": 1,
      "enable": true
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "phi4-mini:latest",
      "model": "phi4-mini:latest",
      "promptLevel": 1,
      "enable": true
    }
  ],
  "embeddingModels": [
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "openai/text-embedding-3-small",
      "model": "text-embedding-3-small",
      "dimension": 1536
    },
    {
      "providerType": "openai",
      "providerId": "openai",
      "id": "openai/text-embedding-3-large",
      "model": "text-embedding-3-large",
      "dimension": 3072
    },
    {
      "providerType": "gemini",
      "providerId": "gemini",
      "id": "gemini/text-embedding-004",
      "model": "text-embedding-004",
      "dimension": 768
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "ollama/nomic-embed-text",
      "model": "nomic-embed-text",
      "dimension": 768
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "ollama/mxbai-embed-large",
      "model": "mxbai-embed-large",
      "dimension": 1024
    },
    {
      "providerType": "ollama",
      "providerId": "ollama",
      "id": "ollama/bge-m3",
      "model": "bge-m3",
      "dimension": 1024
    }
  ],
  "chatModelId": "sonar",
  "applyModelId": "sonar-reasoning",
  "embeddingModelId": "ollama/nomic-embed-text",
  "systemPrompt": "You are running inside Obsidian (a local Markdown note app). Write answers as Obsidian-ready Markdown only.\n\nHard rules:\n- No meta text (no “I’m sorry…”, no “as an AI…”, no discussion about server load).\n- Start with the answer immediately (1–2 sentences).\n- Then give 3–7 bullet points max.\n- If unsure, ask 1 short clarifying question instead of guessing.\n- Keep it under 1200 characters unless I explicitly ask for detail.\n\nCitations:\n- Always include a “Sources” section at the end.\n- In “Sources”, list the web sources as Markdown links using the URLs provided by the API response metadata (e.g., search_results).\n- If no sources are available, write “Sources: (none returned by API)” and do not invent citations.\n\nFormatting:\n- Use headings (##) sparingly (max 2).\n- Prefer bullets over paragraphs.\n",
  "ragOptions": {
    "chunkSize": 1000,
    "thresholdTokens": 1024,
    "minSimilarity": 0,
    "limit": 10,
    "excludePatterns": [],
    "includePatterns": []
  },
  "mcp": {
    "servers": []
  },
  "chatOptions": {
    "includeCurrentFileContent": true,
    "enableTools": true,
    "maxAutoIterations": 1
  }
}